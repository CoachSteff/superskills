# SuperSkills Project Rules for AI Assistants

## 1. Directory Structure & Organization

### Root Directory Maintenance

**CRITICAL: Keep root directory clean and organized**

The project root should ONLY contain these files:
- **WARP.md** - Development notes and current work-in-progress
- **ROADMAP.md** - Project roadmap and future plans
- **CHANGELOG.md** - Version history and release notes
- **README.md** - Main project documentation
- **CONTRIBUTING.md** - Contribution guidelines

**All other documentation and temporary files belong elsewhere:**
- Implementation docs → `dev/` directory
- Test files → `dev/` or `tests/` directory
- Release notes → `dev/` directory
- User guides → `docs/` directory

**When adding new files:**
- ❌ NEVER add temporary test files to root (e.g., `test-podcast-script.md`)
- ❌ NEVER add implementation notes to root (e.g., `IMPLEMENTATION_SUMMARY.md`)
- ❌ NEVER add verification reports to root (e.g., `VERIFICATION.md`)
- ✅ Use `dev/` for development/internal documentation
- ✅ Use `docs/` for user-facing guides
- ✅ Ensure all functionality is tested before committing
- ✅ Document all changes in appropriate files (CHANGELOG.md for releases, dev/ for technical notes)

### Canonical Locations
- **`/superskills/`** - The ONLY canonical directory for all skills (43 total)
- **NEVER create or reference `/new-skills/`** - This directory was deprecated and removed
- All active development happens in `/superskills/`

### Skill Directory Pattern
```
superskills/{skill-name}/
├── {skill-name}.skill      # Optional shortcut (prompt-only skills)
├── SKILL.md                # Skill definition (required)
├── PROFILE.md              # User's personal profile (gitignored)
├── PROFILE.md.template     # Template for users (committed)
├── src/                    # Python implementation (if needed)
│   ├── __init__.py
│   └── {MainClass}.py
├── tests/                  # Tests (if Python skill)
├── requirements.txt        # Dependencies (if Python skill)
└── .env.template           # Credential placeholders (if API skill)
```

---

## 1A. IDE AI Delegation Framework

### When to Use SuperSkills CLI

**Delegate to CLI when:**
- Task requires specialized domain expertise (writing, voice generation, research)
- API integrations needed (ElevenLabs, Gemini, Craft Docs, etc.)
- PROFILE.md personalization required (brand voice, tone-of-voice)
- Multi-step workflows (research → write → edit)
- Batch operations (generate 10 social posts)

**Handle directly when:**
- Code changes, refactoring, debugging
- File manipulation, git operations
- Quick queries, file searches, explanations
- Context-dependent tasks requiring conversation state
- IDE-native operations (linting, testing, formatting)

### Delegation Decision Tree

```
Task Request
  ↓
  ├─ Requires API integration? → YES → Use SuperSkills CLI
  ├─ Needs PROFILE.md personalization? → YES → Use SuperSkills CLI
  ├─ Multi-step workflow? → YES → Use `superskills run <workflow>`
  ├─ Code/file manipulation? → YES → Handle directly
  └─ Quick question/query? → YES → Handle directly
```

### Command Templates

**Single Skill Execution:**
```bash
# Basic call
superskills call <skill-name> "<input>"

# With file input/output
superskills call <skill-name> --input file.txt --output result.md

# With JSON output (for parsing)
superskills call <skill-name> "<input>" --json

# From stdin (for piping)
echo "content" | superskills call <skill-name> --json
```

**Workflow Execution:**
```bash
# Pre-built workflows
superskills run content-creation --topic "AI automation"
superskills run podcast-generation --input script.txt
superskills run training-material --input recording.mp3
superskills run client-engagement --input "https://website.com"

# With JSON output
superskills run content-creation --topic "topic" --json

# Dry-run (preview without execution)
superskills run content-creation --topic "topic" --dry-run
```

**Skill Discovery:**
```bash
# Find skills by capability
superskills discover --query "voice generation"

# Find workflow for task
superskills discover --task "research and write article"

# JSON output for parsing
superskills discover --query "image generation" --json
```

**Metadata Export:**
```bash
# Export all skill metadata
superskills export

# Export as markdown
superskills export --markdown

# Filter by type
superskills export --type prompt
superskills export --has-api

# Save to file
superskills export --output .cursorrules-skills.json
```

### Context Handoff Protocol

**From IDE AI to Skill:**
- Pass minimal necessary context via stdin, temp files, or `--input`
- Don't expose sensitive conversation history
- Use JSON output mode for structured responses
- Parse metadata for execution details

**From Skill to IDE AI:**
- Capture stdout/stderr
- Parse JSON responses when `--json` flag used
- Apply skill output to codebase using IDE AI's file editing tools
- Validate and refine results before delivery to user

### Hybrid Workflow Pattern

**Example: Content Creation**
```
User: "Write LinkedIn post about AI automation"
  ↓
IDE AI orchestration:
  1. Research context (direct file reading if needed)
  2. Delegate: `superskills call researcher "AI automation trends" --json`
  3. Parse JSON output, extract research
  4. Delegate: `superskills call author --input research.md --json`
  5. Review output, make refinements (direct)
  6. Deliver to user
```

**Example: Podcast Workflow**
```
User: "Create podcast episode about productivity"
  ↓
IDE AI orchestration:
  1. Propose: "I'll use content-creation + narrator skills"
  2. Execute: `superskills run content-creation --topic "productivity" --json`
  3. Review script, adjust if needed
  4. Execute: `superskills call narrator --input script.md --content-type podcast --json`
  5. Deliver: MP3 file + transcript
```

### Error Handling Rules

**When skill fails:**
- Parse error from JSON response if `--json` used
- Fall back to direct handling with explanation
- Suggest alternatives or troubleshooting steps
- Never silently fail; always inform user

**Common errors:**
- **Skill not found**: Run `superskills list`, suggest similar skills
- **API key missing**: Point to credential setup docs
- **Timeout**: Show partial results, offer retry
- **Invalid input**: Validate input before delegation

### Skill Capability Quick Reference

**Content Skills:**
- `author` - Ghostwriting in brand voice
- `copywriter` - Marketing copy optimization
- `editor` - Content editing and refinement
- `translator` - Translation and localization

**Media Skills:**
- `narrator` - Voice generation (ElevenLabs)
- `designer` - AI image generation (Gemini)
- `transcriber` - Audio/video transcription
- `videoeditor` - Video editing workflows
- `presenter` - Presentation creation

**Business Skills:**
- `coach` - Coaching session design
- `strategist` - Strategic planning
- `marketer` - Social media scheduling
- `sales` - Sales messaging
- `publisher` - Content distribution

**Technical Skills:**
- `developer` - Code generation
- `scraper` - Web content extraction
- `craft` - Craft Docs integration
- `webmaster` - Website management

**For complete list:** `superskills export --markdown`

### Workflow Orchestration Examples

**Pattern 1: Research → Write → Edit**
```bash
# Trigger: "Research [topic] and write article"
superskills run content-creation --topic "[topic]" --json
```

**Pattern 2: Script → Narrate → Publish**
```bash
# Trigger: "Create podcast from script"
echo "$script" | superskills call narrator --content-type podcast --json
```

**Pattern 3: Scrape → Analyze → Outreach**
```bash
# Trigger: "Research company and create outreach"
superskills run client-engagement --input "https://company.com" --json
```

**Pattern 4: Transcribe → Structure → Edit**
```bash
# Trigger: "Convert recording to training material"
superskills run training-material --input recording.mp3 --json
```

### Integration Best Practices

1. **Observable Execution**: Always log/show skill calls to user
2. **Stateless Skills**: Don't rely on skills maintaining state
3. **Graceful Degradation**: If CLI unavailable, handle with reduced quality
4. **Result Validation**: Review skill output before final delivery
5. **Context Optimization**: Pass only necessary data to skills
6. **JSON Preference**: Use `--json` for structured, parseable responses

---

## 2. Genericization & Personalization Principles

### CRITICAL: Never Hardcode Personal Information

**❌ WRONG:**
```python
# Hardcoded personal info in code
class VoiceGenerator:
    DEFAULT_VOICE = "CoachSteff"
    BRAND_STYLE = "Modern, approachable, science-backed aesthetic"
```

**✅ CORRECT:**
```python
# Generic defaults, user-configurable
class VoiceGenerator:
    def __init__(self, voice_name: str = "Default", brand_style: Optional[str] = None):
        self.voice_name = voice_name
        self.brand_style = brand_style or "Clean, professional design"
```

### Where Personal Content Belongs
- ✅ **PROFILE.md files** (gitignored) - Names, brands, voice characteristics
- ✅ **Configuration files** (JSON/YAML) - Voice settings, style preferences
- ❌ **Source code** - Never hardcode personal info
- ❌ **Docstrings** - Use generic descriptions

---

## 3. PROFILE.md Pattern

### Two-File System
1. **PROFILE.md.template** (committed to git)
   - Generic template with placeholders
   - Shows users what to customize
   - Example: `[Your Name/Brand]`, `[Your Voice Tone]`

2. **PROFILE.md** (gitignored, user-created)
   - User's personal information
   - Created by copying template
   - Never committed to repository

### Template Structure
```markdown
# User Profile

## [Skill Role]
**Name**: [Your Name/Brand]
**Role**: [Your Professional Role]
**Expertise**: [Your expertise areas]

## Characteristics
- **[Trait 1]**: [Your preference]
- **[Trait 2]**: [Your preference]

## Configuration
[How to use this profile with the skill]
```

### Code Integration
```python
# Read from PROFILE.md or config file
def load_profile():
    profile_path = Path(__file__).parent.parent / "PROFILE.md"
    if profile_path.exists():
        # Parse and use user's profile
        return parse_profile(profile_path)
    # Fall back to generic defaults
    return {"name": "Default", "style": "Professional"}
```

---

## 4. Configuration Files for Customization

### Use JSON/YAML for User Settings

**Example: voice_profiles.json**
```json
{
  "narration": {
    "voice_id": "user_voice_id_here",
    "voice_name": "User Voice Name",
    "speed": 0.85,
    "stability": 0.40
  }
}
```

**Code Pattern:**
```python
import json
from pathlib import Path

class ConfigLoader:
    def __init__(self):
        config_path = Path(__file__).parent.parent / "config.json"
        if config_path.exists():
            with open(config_path) as f:
                self.config = json.load(f)
        else:
            self.config = self._get_defaults()
    
    def _get_defaults(self):
        return {
            "voice_name": "Default",
            "speed": 1.0
        }
```

### Benefits
- User-friendly (no code editing needed)
- Validates on load
- Easy to version control template
- Clear separation of code and content

---

## 5. Version Management with CHANGELOG.md

### CRITICAL: CHANGELOG.md Must Be Updated Before Any Commit

**MANDATORY WORKFLOW:**
1. **Before making any code changes**: Read CHANGELOG.md to understand recent changes
2. **During development**: Document changes in `## [Unreleased]` section
3. **Before committing**: Review and update CHANGELOG.md with all changes made
4. **Never commit code without updating CHANGELOG.md** (unless it's a trivial typo fix in docs)

### CHANGELOG.md Update Requirements

**ALWAYS update CHANGELOG.md when:**
- ✅ Adding new skills or features
- ✅ Modifying existing functionality
- ✅ Fixing bugs or issues
- ✅ Changing API interfaces
- ✅ Updating configuration formats
- ✅ Adding/removing dependencies
- ✅ Security patches or improvements
- ✅ Performance improvements
- ✅ Breaking changes
- ✅ Deprecating features
- ✅ Updating CLI commands or flags

**Optional (use judgment):**
- ⚠️ Documentation improvements (significant ones should be noted)
- ⚠️ Internal refactoring (note if it affects behavior or performance)
- ❌ Typo fixes in comments/docs (skip for trivial changes)

### Standard Format (Keep a Changelog)

```markdown
## [Unreleased]

### Added
- New feature or capability description
- Another new feature with context

### Changed
- Modified behavior with explanation
- Updated component with details

### Deprecated
- Feature scheduled for removal (with timeline if known)

### Removed
- Deleted feature or deprecated code

### Fixed
- Bug fix with issue description
- Another fix with context

### Security
- Security-related changes or patches

### Performance
- Performance improvements with measurable impact
```

### CHANGELOG.md Best Practices

**1. Write User-Facing Descriptions**
```markdown
# ❌ BAD - Too technical, no context
### Changed
- Updated skill_executor.py line 45

# ✅ GOOD - Clear impact and context
### Changed
- Skill executor now properly loads skill-specific .env files, fixing credential loading issues
```

**2. Group Related Changes**
```markdown
# ✅ GOOD - Grouped by feature
### Added
- **Model Resolver System**: Automatic resolution of model aliases
  - `claude-3-sonnet-latest` resolves to stable version
  - Automatic fallback on 404 errors
  - Global caching for performance
```

**3. Link to Issues/PRs When Relevant**
```markdown
### Fixed
- Narrator skill voice profile loading (#42)
- API timeout handling in transcriber (#38)
```

**4. Be Specific About Breaking Changes**
```markdown
### Changed
- **BREAKING**: Config format updated from JSON to YAML
  - Old configs will be auto-migrated on first run
  - Manual migration: run `superskills migrate-config`
```

### Pre-Commit CHANGELOG.md Checklist

Before every commit, verify:
- [ ] All code changes are documented in CHANGELOG.md
- [ ] Entries are in `## [Unreleased]` section
- [ ] Entries use correct category (Added/Changed/Fixed/etc.)
- [ ] Descriptions are clear and user-facing
- [ ] Breaking changes are marked as **BREAKING**
- [ ] Related changes are grouped together
- [ ] CHANGELOG.md is committed with code changes

### Pre-Release CHANGELOG.md Review

Before creating a release, AI agents MUST:
1. **Review entire `## [Unreleased]` section**
2. **Verify completeness**: Check if all merged changes are documented
3. **Check for consistency**: Ensure descriptions match actual changes
4. **Validate categorization**: Confirm entries are in correct sections
5. **Add summary**: Write a brief summary at the top of the version section
6. **Version the release**: Move `[Unreleased]` → `[X.Y.Z] - YYYY-MM-DD`
7. **Create new Unreleased section**: Add empty `## [Unreleased]` at top

### Example: Moving from Unreleased to Release

**Before release:**
```markdown
## [Unreleased]

### Added
- New obsidian skill for note management
- Export command with markdown support

### Fixed
- Narrator skill audio quality settings
```

**After release (v2.1.0):**
```markdown
## [Unreleased]

## [2.1.0] - 2025-12-17

### Summary
Feature release: Obsidian integration and export improvements

### Added
- **Obsidian Skill**: Complete note management integration
  - Bidirectional sync with Obsidian vaults
  - Tag-based organization
  - Backlink support
- **Export Enhancements**: 
  - Markdown output format (`--markdown` flag)
  - Improved formatting and readability

### Fixed
- Narrator skill audio quality settings now properly applied
- Voice profile stability parameter respected
```

### Commit Message Integration

Always commit CHANGELOG.md with related code:
```bash
# ✅ GOOD - Atomic commit with changelog
git add superskills/obsidian/ CHANGELOG.md
git commit -m "feat: add obsidian skill for note management"

# ❌ BAD - Code without changelog
git add superskills/obsidian/
git commit -m "feat: add obsidian skill"
# Then later: git add CHANGELOG.md && git commit -m "update changelog"
```

### CHANGELOG.md Anti-Patterns

**❌ AVOID:**
- Committing code without updating CHANGELOG.md
- Generic entries: "Fixed bugs", "Updated code", "Improvements"
- Technical jargon without context: "Refactored BaseExecutor.execute()"
- Forgetting to document breaking changes
- Waiting until release to write CHANGELOG.md entries
- Copying git commit messages verbatim

**✅ DO:**
- Update CHANGELOG.md as you code
- Write clear, user-focused descriptions
- Group related changes under one feature
- Mark breaking changes explicitly
- Review CHANGELOG.md before every commit
- Use CHANGELOG.md to plan releases

---

## 6. Credential Management & Security

### Environment Variables (.env)

**Rules:**
- ✅ Provide `.env.template` with placeholders
- ✅ Add `.env` to `.gitignore` (already done)
- ✅ Use `os.getenv()` with fallback/error handling
- ❌ NEVER commit `.env` files
- ❌ NEVER log API keys

**Example .env.template:**
```bash
# ElevenLabs Configuration
ELEVENLABS_API_KEY=your_api_key_here
ELEVENLABS_VOICE_ID=your_voice_id_here

# Google Gemini Configuration
GEMINI_API_KEY=your_api_key_here
```

**Code Pattern:**
```python
import os

class APIClient:
    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key or os.getenv("SERVICE_API_KEY")
        if not self.api_key:
            raise ValueError(
                "API key not found. Set SERVICE_API_KEY environment variable "
                "or pass api_key parameter."
            )
```

---

## 7. Code Organization & Imports

### Relative Imports Within Skills
```python
# In superskills/narrator/src/Voiceover.py
from .VoiceConfig import VoiceConfig  # ✅ Relative import
from elevenlabs.client import ElevenLabs  # ✅ External package

# ❌ Avoid absolute imports within skill
from superskills.narrator.src.VoiceConfig import VoiceConfig
```

### Module Structure
```python
# superskills/narrator/src/__init__.py
from .Voiceover import VoiceoverGenerator
from .Podcast import PodcastGenerator, PodcastSegment
from .VoiceConfig import VoiceConfig

__all__ = [
    "VoiceoverGenerator",
    "PodcastGenerator", 
    "PodcastSegment",
    "VoiceConfig"
]

__version__ = "1.1.0"
```

### Docstrings - Keep Generic
```python
class ImageGenerator:
    """Generate images using AI providers (Gemini, Midjourney).
    
    Supports multiple platforms and customizable brand styles.
    Brand style can be configured via PROFILE.md or passed as parameter.
    """
    
    # ❌ Don't mention specific users
    # """Generate images for CoachSteff's brand using Gemini."""
```

---

## 8. Documentation Updates

### When to Update Each File

**README.md** - Update when:
- Skill count changes
- Installation steps change
- New major features added

**ARCHITECTURE.md** - Update when:
- Directory structure changes
- New patterns introduced
- Component relationships change

**CONTRIBUTING.md** - Update when:
- Development workflow changes
- Testing requirements change
- New tools/scripts added

**Skill-specific README.md** - Always include:
- Installation instructions
- Configuration options
- Usage examples
- API reference (if Python skill)

---

## 9. Testing Requirements

### Mock All External APIs

**Pattern:**
```python
import pytest
from unittest.mock import patch, Mock

def test_voice_generation(mocker):
    # Mock ElevenLabs API
    mock_client = mocker.patch('elevenlabs.client.ElevenLabs')
    mock_response = Mock()
    mock_response.json.return_value = {"audio": "base64_data"}
    mock_client.return_value.text_to_speech.convert.return_value = [b"audio_data"]
    
    # Test the function
    generator = VoiceoverGenerator()
    result = generator.generate("Test script")
    
    assert result["output_file"].endswith(".mp3")
```

### Test Missing Configuration
```python
def test_missing_env_var():
    """Ensure graceful error when API key missing."""
    with pytest.raises(ValueError, match="API key not found"):
        APIClient()

def test_missing_profile():
    """Ensure defaults work when PROFILE.md missing."""
    generator = VoiceoverGenerator()
    assert generator.voice_name == "Default"
```

### Run Before Committing
```bash
pytest tests/ -v
```

---

## 10. Security & Privacy Rules

### Gitignore Requirements
The following are already gitignored - verify they stay that way:
- `**/PROFILE.md` - Personal profiles
- `.env` - API credentials
- `*.log` - May contain sensitive data
- `output/` - Generated content may be personal
- `WARP.md` - Development notes

### Never Log Sensitive Data
```python
# ✅ Safe logging
logger.info(f"Generated voiceover: {output_path}")

# ❌ Unsafe logging
logger.info(f"Using API key: {api_key}")  # NEVER!
logger.debug(f"User profile: {profile_data}")  # NEVER!
```

### Input Validation
```python
def generate_image(prompt: str, api_key: str):
    # Validate before API call
    if not prompt or len(prompt) > 1000:
        raise ValueError("Invalid prompt length")
    
    if not api_key or not api_key.startswith("sk-"):
        raise ValueError("Invalid API key format")
```

---

## Quick Reference Checklist

When creating or modifying skills:

- [ ] Code is in `/superskills/{skill-name}/`
- [ ] No hardcoded personal info (names, brands, voices)
- [ ] Configuration via JSON/YAML or PROFILE.md
- [ ] PROFILE.md.template created (generic placeholders)
- [ ] .env.template created (if uses APIs)
- [ ] Tests written (APIs mocked)
- [ ] **CHANGELOG.md updated in `## [Unreleased]` section**
- [ ] **CHANGELOG.md entry is user-facing and descriptive**
- [ ] **CHANGELOG.md committed with code changes**
- [ ] Documentation updated (README.md if needed)
- [ ] No credentials in code or logs
- [ ] Relative imports used within skill

---

## Pre-Commit Checklist

Before every commit, verify:

- [ ] **Read CHANGELOG.md** to understand recent changes
- [ ] **Updated CHANGELOG.md** with all code changes made
- [ ] CHANGELOG.md entries are in correct category (Added/Changed/Fixed/etc.)
- [ ] Descriptions are clear and user-focused (not technical jargon)
- [ ] Breaking changes marked with **BREAKING**
- [ ] Tests pass (`pytest tests/ -v`)
- [ ] Code follows project conventions
- [ ] No personal information in committed files
- [ ] CHANGELOG.md and code committed together

---

## Pre-Release Checklist

Before creating any release, AI agents MUST:

- [ ] **Review entire `## [Unreleased]` section** in CHANGELOG.md
- [ ] Verify all merged changes are documented
- [ ] Ensure descriptions match actual changes
- [ ] Validate correct categorization of changes
- [ ] Add release summary at top of version section
- [ ] Move `[Unreleased]` → `[X.Y.Z] - YYYY-MM-DD`
- [ ] Create new empty `## [Unreleased]` section at top
- [ ] Update version numbers in code (if applicable)
- [ ] Run full test suite
- [ ] Verify documentation is up-to-date

---

## Examples of Common Scenarios

### Scenario 1: Adding a New Voice Setting
❌ **Wrong:** Hardcode in class constant
✅ **Right:** Add to `voice_profiles.json`, document in `PROFILE.md.template`

### Scenario 2: User Wants Custom Brand Style
❌ **Wrong:** Edit source code to change BRAND_STYLE constant
✅ **Right:** Pass `brand_style` parameter or define in PROFILE.md

### Scenario 3: New Skill Needs API Key
❌ **Wrong:** Put in config.py or constants.py
✅ **Right:** Create `.env.template`, use `os.getenv()`, document in README.md

### Scenario 4: Refactoring Skill Implementation
❌ **Wrong:** Skip updating CHANGELOG.md
✅ **Right:** Add note in CHANGELOG.md [Unreleased] → Changed section

---

## 11. Pre-Execution Guardrails for AI Assistants

### CRITICAL: Check Before Any Skill Execution

Before executing ANY task involving SuperSkills, **ALWAYS verify**:

**1. CLI Capability Check**
```bash
# Does the CLI already have this capability?
superskills list              # List all skills
superskills call <skill> -h   # Check skill capabilities
```

**2. Workflow Existence Check**
```bash
# Does a workflow already exist for this task?
ls workflows/                 # Check available workflows
cat workflows/<name>/README.md   # Read workflow documentation
cat workflows/<name>/config.yaml # Check output directories
```

**3. Output Directory Validation**
- ❌ **NEVER** create output directories in skill folders (`superskills/<skill>/output/`)
- ✅ **ALWAYS** use workflow output directories (`workflows/<workflow>/output/`)
- ✅ **OR** use CLI with explicit `--output` flag pointing to workflow output
- ✅ **READ** config.yaml to verify correct output path before generation

**4. Script Creation Policy**
- ❌ **NEVER** create new Python scripts for one-off executions
- ❌ **NEVER** create standalone generation scripts that bypass CLI/workflows
- ✅ **USE** `superskills call <skill>` for API-based tasks
- ✅ **USE** `superskills run <workflow>` for multi-step tasks
- ✅ **ONLY** create scripts when building reusable workflows (in `workflows/` directory)

### Decision Tree: Task Execution

```
Task Request
  ↓
  ├─ Is it API integration? → YES → superskills call <skill>
  ├─ Is it multi-step? → YES → Check workflows/ → superskills run <workflow>
  ├─ Does workflow exist? → YES → USE IT (don't recreate)
  ├─ Need custom workflow? → YES → Create in workflows/, not superskills/<skill>/
  └─ Simple code task? → YES → Handle directly with IDE tools
```

### Output Location Rules

**Workflows:**
- Output dir: `workflows/<workflow-name>/output/` (per config.yaml)
- Input dir: `workflows/<workflow-name>/inbox/` (per config.yaml)
- All generated content goes to workflow's output directory

**Skills:**
- Skill folders: Implementation code only (src/, tests/, SKILL.md)
- NO output directories in `superskills/<skill>/`
- Skills output to locations specified via CLI `--output` flag

**Example: Podcast Generation**
```bash
# ❌ WRONG: Create new script in superskills/narrator/
python superskills/narrator/my_new_script.py

# ✅ RIGHT: Use workflow with watch mode
cp script.md workflows/podcast-generation/input/
superskills run podcast-generation --watch

# ✅ RIGHT: Use workflow with batch mode
cp script1.md script2.md workflows/podcast-generation/input/
superskills run podcast-generation --batch

# ✅ RIGHT: Use CLI with single file
superskills run podcast-generation --input script.md
```

### Common Mistakes to Avoid

**Mistake 1: Creating One-Off Scripts**
- ❌ `superskills/narrator/generate_my_podcast.py`
- ✅ Use existing tools: `superskills run <workflow>`

**Mistake 2: Wrong Output Directory**
- ❌ Output to `superskills/<skill>/output/`
- ✅ Output to `workflows/<workflow>/output/` per workflow.yaml

**Mistake 3: Ignoring Existing Workflows**
- ❌ Building custom script when workflow exists
- ✅ Check `workflows/` first, read README.md and workflow.yaml

**Mistake 4: Hardcoding Paths**
- ❌ `output_dir = "superskills/narrator/output"`
- ✅ Read from config.yaml or use CLI `--output` flag

### Verification Checklist

Before committing/completing any task:

- [ ] No new scripts in `superskills/<skill>/` (except workflow infrastructure)
- [ ] No output directories in `superskills/<skill>/`
- [ ] Generated files in correct workflow output directory
- [ ] Used CLI or existing workflow (not custom one-off script)
- [ ] Read config.yaml to verify output paths
- [ ] Followed .cursorrules delegation decision tree (§1A)

### When to Escalate

Stop and ask user if:
- Workflow doesn't exist and task seems complex
- Output location unclear from config.yaml
- CLI doesn't support required parameters
- Multiple valid approaches exist

---

**Last Updated:** December 8, 2024  
**Project:** SuperSkills v1.1.1  
**Maintainer:** See CONTRIBUTING.md
